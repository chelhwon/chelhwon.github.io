<!DOCTYPE html>
<html>    
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Previous Projects</title>
        <meta name="description" content="Previous Projects">
        <link rel="stylesheet" href="main.css">
    </head>
    
    <body>
        <h1>Previous Projects</h1>
        
        
        
        <h3><a href="Fxpal.html">High-Quality Capture of Documents on a Cluttered Tabletop with a 4K Video Camera</a></h3>
        <h4 style="text-align:right">FXPAL, Summer Intern 2014</h4>
        <p>
            <img src="images/FXPAL/img.png" alt="fxpal" style="width:650px">
            We present a novel system for detecting and capturing paper documents on a tabletop using a 4K video camera mounted
            overhead
            on pan-tilt servos. Our automated system first finds paper documents on a cluttered tabletop based on a text probability
            map, and then takes a sequence of high-resolution frames of the located document to reconstruct a high quality and fronto
            -parallel document page image. The quality of the resulting images enables OCR processing on the whole page. We performed a
            preliminary evaluation on a small set of 10 document pages and our proposed system achieved 98% accuracy with the open
            source Tesseract OCR engine.</p>
        
        
        
        
        <h3><a href="SaliencyDetection.html">Visual Salinecy in noisy images</a></h3>
        <h4 style="text-align:right">Multi-Dimensional Signal Processing Lab., UC Santa Cruz</h4>
        <p>
            <table>
            <tr>
                <td><img src="images/JOV/Icon.gif" alt="saliency gif" style="height:100px"></td>
                <td><img src="images/JOV/img.png" alt="saliency" sytle="height:200px;"></td>
            </tr></table>
            
            The human visual system possesses the remarkable ability to pick out salient objects in images. Even more impressive is 
            its ability to do the very same in the presence of disturbances. In particular, the ability persists despite the presence
            of noise, poor weather, and other impediments to perfect vision. Meanwhile, noise can significantly degrade the accuracy of
            automated computational saliency detection algorithms. In this paper we set out to remedy this shortcoming. Existing
            computational saliency models generally assume that the given image is clean and a fundamental and explicit treatment of
            saliency in noisy images is missing from the literature. Here we propose a novel and statistically sound method for
            estimating saliency based on a non-parametric regression framework, and investigate the stability of saliency models for
            noisy images and analyze how state-of-the-art computational models respond to noisy visual stimuli. The proposed model of
            saliency at a pixel of interest is a data-dependent weighted average of dissimilarities between a center patch around that
            pixel and other patches. In order to further enhance the degree of accuracy in predicting the human fixations and of
            stability to noise, we incorporate a global and multi-scale approach by extending the local analysis window to the entire
            input image, even further to multiple scaled copies of the image. Our method consistently outperforms six other state-of-               the-art models for both noise-free and noisy cases.
        </p>




        <h3><a href="http://isrc.skku.ac.kr/team/team_detail.php?team_code=1">Dependable statistical fusion for 3D object recognition and pose estimation</a></h3> 
        <h4 style="text-align:right">Intelligent Systems Research Center, Sungkyunkwan University, Korea</h4>
        <p>
            <img src="images/ISRC/img.png" alt="robot" style="height:300px;">
            This research presents a novel probabilistic recognition framework for recognition and pose estimation of 3D objects 
            in real environment. The proposed approach features 1) the automatic selection and collection of an optimal set of
            evidences based on in-situ monitoring of environmental variations, 2) the derivation of multiple interpretations, as
            particles representing possible object poses in 3D space, and the assignment of their probabilities based on matching the
            object model with evidences, and 3) the fusion of interpretations in time with the additional evidences obtained from a
            sequence of images.
        </p>
    
    
        <h3><a href="http://ilab.cs.ucsb.edu/index.php/component/content/article/12/55">Using Structured Light for Efficient Depth 
            Edge Detection</a></h3>
        <h4 style="text-align:right">Computer Vision Lab., Sungkyunkwan University, Korea</h4>
        <img src="images/depth_edge/img.png" alt="depth edge" style="width:550px;"></td>
        <p>This research describes a novel approach that accurately detects depth edges with cluttered inner texture edges
                effectively ignored. We strategically project structured light and exploit distortion of the light pattern in the
                structured light image along depth discontinuities to reliably detect depth edges. In practice, distortion along depth
                discontinuities may not occur or be large enough to detect depending on the distance from the camera or projector. We
                present methods that guarantee the occurrence of the distortion along depth discontinu- ities for a continuous range of
                object location. Experimental results show that the proposed method accurately detects depth edges of shapes of human
                hands and bodies as well as general objects.</p>
        


        <h3>Nexteye Machine Vision</h3>
        <h4 style="text-align:right">Nexteye machine vision Co., Ltd., Korea</h4>
        <h4>Vision based profile monitoring of plastic tube</h4>
        <p><img src="images/Nexteye/img1.png" alt="robot" style="width:350px;">
            This plastic tube profile monitoring system is a series of 6 calibrated camera-laser units to monitor deformation.
                Projecting a line of laser light onto a three- dimensionally shaped surface produces a line of illumination that
                appears distorted, and can be used to reveal surface profiles of a part of plastic tube from each camera-laser unit.
                The individual surface profiles are combined to obtain the whole profile of plastic tube.
        </p>
        

        <h4>Bullet defect detection system</h4>
        <p>
            <img src="images/Nexteye/img2.png" alt="robot" style="width:350px;">
            Dent, dirty and smear on the case of bullet are detected by projecting a stripe light patterns onto the surface of 
                the bullet and observing distortion in the patterns.
            
        </p>
        
    </body>
</html>
